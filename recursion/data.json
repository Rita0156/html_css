{
    "3":{
       "inputs":{
          "string":"openpose"
       },
       "class_type":"String to Text"
    },
    "4":{
       "inputs":{
          "string":"softedge"
       },
       "class_type":"String to Text"
    },
    "5":{
       "inputs":{
          "delimiter":"",
          "clean_whitespace":"true",
          "text_a":[
             "94",
             0
          ],
          "text_b":[
             "3",
             0
          ]
       },
       "class_type":"Text Concatenate"
    },
    "6":{
       "inputs":{
          "delimiter":"",
          "clean_whitespace":"true",
          "text_a":[
             "94",
             0
          ],
          "text_b":[
             "4",
             0
          ]
       },
       "class_type":"Text Concatenate"
    },
    "9":{
       "inputs":{
          "directory":[
             "5",
             0
          ],
          "image_load_cap":[
             "11",
             0
          ],
          "start_index":[
             "12",
             0
          ]
       },
       "class_type":"LoadImagesFromDirectory"
    },
    "11":{
       "inputs":{
          "value":2
       },
       "class_type":"INTConstant"
    },
    "12":{
       "inputs":{
          "value":0
       },
       "class_type":"INTConstant"
    },
    "14":{
       "inputs":{
          "directory":[
             "6",
             0
          ],
          "image_load_cap":[
             "11",
             0
          ],
          "start_index":[
             "12",
             0
          ]
       },
       "class_type":"LoadImagesFromDirectory"
    },
    "20":{
       "inputs":{
          "control_net_name":"fp16/control_openpose-fp16.safetensors"
       },
       "class_type":"ControlNetLoader"
    },
    "24":{
       "inputs":{
          "control_net_name":"control_v11p_sd15_softedge.pth"
       },
       "class_type":"ControlNetLoader"
    },
    "54":{
       "inputs":{
          "text":[
             "180",
             0
          ],
          "clip":[
             "59",
             5
          ]
       },
       "class_type":"CLIPTextEncode"
    },
    "56":{
       "inputs":{
          "text":[
             "181",
             0
          ],
          "clip":[
             "59",
             5
          ]
       },
       "class_type":"CLIPTextEncode"
    },
    "59":{
       "inputs":{
          "ckpt_name":"illusionmix_.safetensors",
          "vae_name":"Baked VAE",
          "clip_skip":-1,
          "lora_name":"None",
          "lora_model_strength":1.0,
          "lora_clip_strength":1.0,
          "positive":"CLIP_POSITIVE",
          "negative":"CLIP_NEGATIVE",
          "token_normalization":"mean",
          "weight_interpretation":"comfy++",
          "empty_latent_width":512,
          "empty_latent_height":512,
          "batch_size":1,
          "lora_stack":[
             "60",
             0
          ]
       },
       "class_type":"Efficient Loader"
    },
    "60":{
       "inputs":{
          "input_mode":"advanced",
          "lora_count":1,
          "lora_name_1":"add_detail.safetensors",
          "lora_wt_1":1,
          "model_str_1":1,
          "clip_str_1":1,
          "lora_name_2":"None",
          "lora_wt_2":1,
          "model_str_2":1,
          "clip_str_2":1,
          "lora_name_3":"None",
          "lora_wt_3":1,
          "model_str_3":1,
          "clip_str_3":1,
          "lora_name_4":"None",
          "lora_wt_4":1,
          "model_str_4":1,
          "clip_str_4":1,
          "lora_name_5":"None",
          "lora_wt_5":1,
          "model_str_5":1,
          "clip_str_5":1,
          "lora_name_6":"None",
          "lora_wt_6":1,
          "model_str_6":1,
          "clip_str_6":1,
          "lora_name_7":"None",
          "lora_wt_7":1,
          "model_str_7":1,
          "clip_str_7":1,
          "lora_name_8":"None",
          "lora_wt_8":1,
          "model_str_8":1,
          "clip_str_8":1,
          "lora_name_9":"None",
          "lora_wt_9":1,
          "model_str_9":1,
          "clip_str_9":1,
          "lora_name_10":"None",
          "lora_wt_10":1,
          "model_str_10":1,
          "clip_str_10":1,
          "lora_name_11":"None",
          "lora_wt_11":1,
          "model_str_11":1,
          "clip_str_11":1,
          "lora_name_12":"None",
          "lora_wt_12":1,
          "model_str_12":1,
          "clip_str_12":1,
          "lora_name_13":"None",
          "lora_wt_13":1,
          "model_str_13":1,
          "clip_str_13":1,
          "lora_name_14":"None",
          "lora_wt_14":1,
          "model_str_14":1,
          "clip_str_14":1,
          "lora_name_15":"None",
          "lora_wt_15":1,
          "model_str_15":1,
          "clip_str_15":1,
          "lora_name_16":"None",
          "lora_wt_16":1,
          "model_str_16":1,
          "clip_str_16":1,
          "lora_name_17":"None",
          "lora_wt_17":1,
          "model_str_17":1,
          "clip_str_17":1,
          "lora_name_18":"None",
          "lora_wt_18":1,
          "model_str_18":1,
          "clip_str_18":1,
          "lora_name_19":"None",
          "lora_wt_19":1,
          "model_str_19":1,
          "clip_str_19":1,
          "lora_name_20":"None",
          "lora_wt_20":1,
          "model_str_20":1,
          "clip_str_20":1,
          "lora_name_21":"None",
          "lora_wt_21":1,
          "model_str_21":1,
          "clip_str_21":1,
          "lora_name_22":"None",
          "lora_wt_22":1,
          "model_str_22":1,
          "clip_str_22":1,
          "lora_name_23":"None",
          "lora_wt_23":1,
          "model_str_23":1,
          "clip_str_23":1,
          "lora_name_24":"None",
          "lora_wt_24":1,
          "model_str_24":1,
          "clip_str_24":1,
          "lora_name_25":"None",
          "lora_wt_25":1,
          "model_str_25":1,
          "clip_str_25":1,
          "lora_name_26":"None",
          "lora_wt_26":1,
          "model_str_26":1,
          "clip_str_26":1,
          "lora_name_27":"None",
          "lora_wt_27":1,
          "model_str_27":1,
          "clip_str_27":1,
          "lora_name_28":"None",
          "lora_wt_28":1,
          "model_str_28":1,
          "clip_str_28":1,
          "lora_name_29":"None",
          "lora_wt_29":1,
          "model_str_29":1,
          "clip_str_29":1,
          "lora_name_30":"None",
          "lora_wt_30":1,
          "model_str_30":1,
          "clip_str_30":1,
          "lora_name_31":"None",
          "lora_wt_31":1,
          "model_str_31":1,
          "clip_str_31":1,
          "lora_name_32":"None",
          "lora_wt_32":1,
          "model_str_32":1,
          "clip_str_32":1,
          "lora_name_33":"None",
          "lora_wt_33":1,
          "model_str_33":1,
          "clip_str_33":1,
          "lora_name_34":"None",
          "lora_wt_34":1,
          "model_str_34":1,
          "clip_str_34":1,
          "lora_name_35":"None",
          "lora_wt_35":1,
          "model_str_35":1,
          "clip_str_35":1,
          "lora_name_36":"None",
          "lora_wt_36":1,
          "model_str_36":1,
          "clip_str_36":1,
          "lora_name_37":"None",
          "lora_wt_37":1,
          "model_str_37":1,
          "clip_str_37":1,
          "lora_name_38":"None",
          "lora_wt_38":1,
          "model_str_38":1,
          "clip_str_38":1,
          "lora_name_39":"None",
          "lora_wt_39":1,
          "model_str_39":1,
          "clip_str_39":1,
          "lora_name_40":"None",
          "lora_wt_40":1,
          "model_str_40":1,
          "clip_str_40":1,
          "lora_name_41":"None",
          "lora_wt_41":1,
          "model_str_41":1,
          "clip_str_41":1,
          "lora_name_42":"None",
          "lora_wt_42":1,
          "model_str_42":1,
          "clip_str_42":1,
          "lora_name_43":"None",
          "lora_wt_43":1,
          "model_str_43":1,
          "clip_str_43":1,
          "lora_name_44":"None",
          "lora_wt_44":1,
          "model_str_44":1,
          "clip_str_44":1,
          "lora_name_45":"None",
          "lora_wt_45":1,
          "model_str_45":1,
          "clip_str_45":1,
          "lora_name_46":"None",
          "lora_wt_46":1,
          "model_str_46":1,
          "clip_str_46":1,
          "lora_name_47":"None",
          "lora_wt_47":1,
          "model_str_47":1,
          "clip_str_47":1,
          "lora_name_48":"None",
          "lora_wt_48":1,
          "model_str_48":1,
          "clip_str_48":1,
          "lora_name_49":"None",
          "lora_wt_49":1,
          "model_str_49":1,
          "clip_str_49":1
       },
       "class_type":"LoRA Stacker"
    },
    "70":{
       "inputs":{
          "model_name":"mm_sd_v15.fp16.safetensors",
          "beta_schedule":"autoselect",
          "motion_scale":1,
          "apply_v2_models_properly":true,
          "model":[
             "169",
             0
          ],
          "context_options":[
             "75",
             0
          ],
          "ad_settings":[
             "76",
             0
          ],
          "sample_settings":[
             "77",
             0
          ]
       },
       "class_type":"ADE_AnimateDiffLoaderWithContext"
    },
    "75":{
       "inputs":{
          "context_length":16,
          "context_stride":1,
          "context_overlap":4,
          "context_schedule":"uniform",
          "closed_loop":false,
          "fuse_method":"flat",
          "use_on_equal_length":false,
          "start_percent":0,
          "guarantee_steps":1
       },
       "class_type":"ADE_AnimateDiffUniformContextOptions"
    },
    "76":{
       "inputs":{
          "motion_pe_stretch":0,
          "min_motion_scale":1,
          "max_motion_scale":1
       },
       "class_type":"ADE_AnimateDiffModelSettingsSimple"
    },
    "77":{
       "inputs":{
          "batch_offset":0,
          "noise_type":"default",
          "seed_gen":"comfy",
          "seed_offset":0,
          "adapt_denoise_steps":false,
          "noise_layers":[
             "78",
             0
          ],
          "iteration_opts":[
             "79",
             0
          ]
       },
       "class_type":"ADE_AnimateDiffSamplingSettings"
    },
    "78":{
       "inputs":{
          "batch_offset":0,
          "noise_type":"default",
          "seed_gen_override":"comfy",
          "seed_offset":0,
          "noise_weight":0.5,
          "balance_multiplier":1
       },
       "class_type":"ADE_NoiseLayerAddWeighted"
    },
    "79":{
       "inputs":{
          "iterations":1,
          "filter":"butterworth",
          "d_s":0.25,
          "d_t":0.25,
          "n_butterworth":4,
          "sigma_step":999,
          "apply_to_1st_iter":false,
          "init_type":"DinkInit_v1",
          "iter_batch_offset":0,
          "iter_seed_offset":1
       },
       "class_type":"ADE_IterationOptsFreeInit"
    },
    "80":{
       "inputs":{
          "b1":1.3,
          "b2":1.4,
          "s1":0.9,
          "s2":0.2,
          "model":[
             "70",
             0
          ]
       },
       "class_type":"FreeU_V2"
    },
    "81":{
       "inputs":{
          "seed":[
             "165",
             0
          ],
          "steps":25,
          "cfg":5.0,
          "sampler_name":"dpmpp_2m",
          "scheduler":"karras",
          "denoise":0.6,
          "preview_method":"none",
          "vae_decode":"true",
          "model":[
             "80",
             0
          ],
          "positive":[
             "195",
             0
          ],
          "negative":[
             "195",
             1
          ],
          "latent_image":[
             "208",
             0
          ],
          "optional_vae":[
             "59",
             4
          ]
       },
       "class_type":"KSampler (Efficient)"
    },
    "83":{
       "inputs":{
          "pixels":[
             "189",
             0
          ],
          "vae":[
             "59",
             4
          ]
       },
       "class_type":"VAEEncode"
    },
    "94":{
       "inputs":{
          "string":"/media/azazul/PRS/projects/ajgDiffusion/video-to-anim-output/output_11/"
       },
       "class_type":"String to Text"
    },
    "131":{
       "inputs":{
          "guide_size":512.0,
          "guide_size_for":true,
          "max_size":1024.0,
          "seed":[
             "165",
             0
          ],
          "steps":20,
          "cfg":8.0,
          "sampler_name":"dpmpp_2m",
          "scheduler":"karras",
          "denoise":0.25,
          "refiner_ratio":0.2,
          "image_frames":[
             "81",
             5
          ],
          "segs":[
             "132",
             0
          ],
          "basic_pipe":[
             "138",
             0
          ]
       },
       "class_type":"SEGSDetailerForAnimateDiff"
    },
    "132":{
       "inputs":{
          "bbox_threshold":0.54,
          "bbox_dilation":0,
          "crop_factor":2.5,
          "drop_size":50,
          "sub_threshold":1.0,
          "sub_dilation":10,
          "sub_bbox_expansion":0,
          "sam_mask_hint_threshold":0.7,
          "masking_mode":"Pivot SEGS",
          "segs_pivot":"Combined mask",
          "bbox_detector":[
             "134",
             0
          ],
          "image_frames":[
             "81",
             5
          ],
          "sam_model_opt":[
             "137",
             0
          ],
          "segm_detector_opt":[
             "136",
             1
          ]
       },
       "class_type":"ImpactSimpleDetectorSEGS_for_AD"
    },
    "134":{
       "inputs":{
          "model_name":"bbox/face_yolov8m.pt"
       },
       "class_type":"UltralyticsDetectorProvider"
    },
    "136":{
       "inputs":{
          "model_name":"segm/person_yolov8m-seg.pt"
       },
       "class_type":"UltralyticsDetectorProvider"
    },
    "137":{
       "inputs":{
          "model_name":"sam_vit_b_01ec64.pth",
          "device_mode":"Prefer GPU"
       },
       "class_type":"SAMLoader"
    },
    "138":{
       "inputs":{
          "basic_pipe":[
             "143",
             0
          ],
          "model":[
             "143",
             1
          ],
          "clip":[
             "143",
             2
          ],
          "vae":[
             "143",
             3
          ],
          "positive":[
             "145",
             0
          ],
          "negative":[
             "143",
             5
          ]
       },
       "class_type":"EditBasicPipe"
    },
    "139":{
       "inputs":{
          "model":[
             "81",
             0
          ],
          "clip":[
             "59",
             5
          ],
          "vae":[
             "81",
             4
          ],
          "positive":[
             "81",
             1
          ],
          "negative":[
             "81",
             2
          ]
       },
       "class_type":"ToBasicPipe"
    },
    "143":{
       "inputs":{
          "basic_pipe":[
             "139",
             0
          ]
       },
       "class_type":"FromBasicPipe_v2"
    },
    "145":{
       "inputs":{
          "text":"Beautiful facial features, beautiful face, sharp eyes, detailed face",
          "clip":[
             "143",
             2
          ]
       },
       "class_type":"CLIPTextEncode"
    },
    "146":{
       "inputs":{
          "feather":5,
          "alpha":255,
          "image":[
             "81",
             5
          ],
          "segs":[
             "131",
             0
          ]
       },
       "class_type":"SEGSPaste"
    },
    "151":{
       "inputs":{
          "output_path":[
             "164",
             0
          ],
          "filename_prefix":"GeneretedImage",
          "filename_delimiter":"_",
          "filename_number_padding":9,
          "filename_number_start":"false",
          "extension":"png",
          "quality":100,
          "lossless_webp":"false",
          "overwrite_mode":"false",
          "show_history":"false",
          "show_history_by_prefix":"true",
          "embed_workflow":"true",
          "show_previews":"true",
          "images":[
             "146",
             0
          ]
       },
       "class_type":"Image Save"
    },
    "163":{
       "inputs":{
          "string":"generatedimage"
       },
       "class_type":"String to Text"
    },
    "164":{
       "inputs":{
          "delimiter":"",
          "clean_whitespace":"true",
          "text_a":[
             "94",
             0
          ],
          "text_b":[
             "163",
             0
          ]
       },
       "class_type":"Text Concatenate"
    },
    "165":{
       "inputs":{
          "seed":406138945797436
       },
       "class_type":"Seed (rgthree)"
    },
    "169":{
       "inputs":{
          "weight":0.4,
          "noise":0.2,
          "weight_type":"linear",
          "start_at":0.42,
          "end_at":1.0,
          "unfold_batch":false,
          "ipadapter":[
             "170",
             0
          ],
          "clip_vision":[
             "171",
             0
          ],
          "image":[
             "172",
             0
          ],
          "model":[
             "59",
             0
          ]
       },
       "class_type":"IPAdapterApply"
    },
    "170":{
       "inputs":{
          "ipadapter_file":"ip-adapter_sd15_light.safetensors"
       },
       "class_type":"IPAdapterModelLoader"
    },
    "171":{
       "inputs":{
          "clip_name":"ipadapter_image_encoder_sd15.safetensors"
       },
       "class_type":"CLIPVisionLoader"
    },
    "172":{
       "inputs":{
          "interpolation":"BICUBIC",
          "crop_position":"pad",
          "sharpening":1.0,
          "image":[
             "189",
             0
          ]
       },
       "class_type":"PrepImageForClipVision"
    },
    "175":{
       "inputs":{
          "images":[
             "146",
             0
          ]
       },
       "class_type":"PreviewImage"
    },
    "180":{
       "inputs":{
          "text":"glamorous photo of a cute girl, solo, short hair, shirt, long sleeves, 1girl, standing, female focus, shorts, indoors, hand up, hood, hoodie, feet out of frame, black shorts, hood down, realistic, white hoodie, embedding:SkinHairDetail . high fashion, luxurious, extravagant, stylish, sensual, opulent, elegance, stunning beauty, professional, high contrast, detailed, , fill lighting, eye level, Hasselblad X1D II, Porta 160, Voigtl√§nder Nokton 50mm f1.1, sharp focus on subject, masterpiece, absurdres, intricate, 8k, high detail, sharp, skin details, professional colorgraded"
       },
       "class_type":"Text Multiline"
    },
    "181":{
       "inputs":{
          "text":"ugly, deformed, noisy, blurry, distorted, grainy, sketch, low contrast, dull, plain, modest, small breasts, medium breasts, mole, moles, freckles, closed mouth, closed eyes, (worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3), (crossed eyes, blurry eyes, blind, bad eyes, ugly eyes, dead eyes)"
       },
       "class_type":"Text Multiline"
    },
    "182":{
       "inputs":{
          "select":[
             "187",
             0
          ],
          "sel_mode":true,
          "input1":[
             "185",
             0
          ],
          "input2":[
             "189",
             0
          ]
       },
       "class_type":"ImpactSwitch"
    },
    "183":{
       "inputs":{
          "image":[
             "189",
             0
          ]
       },
       "class_type":"GetImageSize+"
    },
    "184":{
       "inputs":{
          "width":[
             "183",
             0
          ],
          "height":[
             "183",
             1
          ],
          "red":255,
          "green":255,
          "blue":255
       },
       "class_type":"Image Blank"
    },
    "185":{
       "inputs":{
          "repeats":[
             "189",
             2
          ],
          "images":[
             "184",
             0
          ]
       },
       "class_type":"ImageBatchRepeatInterleaving"
    },
    "186":{
       "inputs":{
          "boolean_number":1
       },
       "class_type":"Logic Boolean"
    },
    "187":{
       "inputs":{
          "expression":"a+1",
          "a":[
             "186",
             1
          ]
       },
       "class_type":"MathExpression|pysssss"
    },
    "189":{
       "inputs":{
          "directory":[
             "199",
             0
          ],
          "image_load_cap":[
             "11",
             0
          ],
          "start_index":[
             "12",
             0
          ]
       },
       "class_type":"LoadImagesFromDirectory"
    },
    "192":{
       "inputs":{
          "channel":"red",
          "image":[
             "182",
             0
          ]
       },
       "class_type":"ImageToMask"
    },
    "194":{
       "inputs":{
          "strength":0.8,
          "start_percent":0.0,
          "end_percent":0.8,
          "positive":[
             "54",
             0
          ],
          "negative":[
             "56",
             0
          ],
          "control_net":[
             "20",
             0
          ],
          "image":[
             "9",
             0
          ],
          "mask_optional":[
             "192",
             0
          ]
       },
       "class_type":"ACN_AdvancedControlNetApply"
    },
    "195":{
       "inputs":{
          "strength":0.8,
          "start_percent":0.0,
          "end_percent":0.9500000000000001,
          "positive":[
             "194",
             0
          ],
          "negative":[
             "194",
             1
          ],
          "control_net":[
             "24",
             0
          ],
          "image":[
             "14",
             0
          ],
          "mask_optional":[
             "192",
             0
          ]
       },
       "class_type":"ACN_AdvancedControlNetApply"
    },
    "198":{
       "inputs":{
          "string":""
       },
       "class_type":"String to Text"
    },
    "199":{
       "inputs":{
          "delimiter":"",
          "clean_whitespace":"true",
          "text_a":[
             "94",
             0
          ],
          "text_b":[
             "198",
             0
          ]
       },
       "class_type":"Text Concatenate"
    },
    "200":{
       "inputs":{
          "input":[
             "189",
             2
          ],
          "output":""
       },
       "class_type":"Display Int (rgthree)"
    },
    "208":{
       "inputs":{
          "upscale_method":"nearest-exact",
          "width":[
             "217",
             0
          ],
          "height":[
             "216",
             0
          ],
          "crop":"disabled",
          "samples":[
             "83",
             0
          ]
       },
       "class_type":"LatentUpscale"
    },
    "210":{
       "inputs":{
          "image":[
             "189",
             0
          ]
       },
       "class_type":"GetImageSize+"
    },
    "211":{
       "inputs":{
          "value":1024
       },
       "class_type":"INTConstant"
    },
    "212":{
       "inputs":{
          "value":1
       },
       "class_type":"FloatConstant"
    },
    "213":{
       "inputs":{
          "expression":"(b/a)",
          "a":[
             "210",
             0
          ],
          "b":[
             "211",
             0
          ]
       },
       "class_type":"MathExpression|pysssss"
    },
    "214":{
       "inputs":{
          "expression":"(b/a)",
          "a":[
             "210",
             1
          ],
          "b":[
             "211",
             0
          ]
       },
       "class_type":"MathExpression|pysssss"
    },
    "215":{
       "inputs":{
          "expression":"min(a,b)",
          "a":[
             "213",
             1
          ],
          "b":[
             "214",
             1
          ]
       },
       "class_type":"MathExpression|pysssss"
    },
    "216":{
       "inputs":{
          "expression":"a*b*c",
          "a":[
             "215",
             0
          ],
          "b":[
             "210",
             1
          ],
          "c":[
             "212",
             0
          ]
       },
       "class_type":"MathExpression|pysssss"
    },
    "217":{
       "inputs":{
          "expression":"a*b*c",
          "a":[
             "215",
             0
          ],
          "b":[
             "210",
             0
          ],
          "c":[
             "212",
             0
          ]
       },
       "class_type":"MathExpression|pysssss"
    }
 }